{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjHoMwqAykrVValvTn6sx+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2211cs020598/AD-assignments/blob/main/Day_11.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Day-11\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "paragraph = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
        "Tokenization is one of the first steps in NLP, breaking text into sentences or words. It is crucial for tasks like text analysis, machine translation, and sentiment analysis.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "sentences = nltk.sent_tokenize(paragraph)\n",
        "\n",
        "\n",
        "words = nltk.word_tokenize(paragraph)\n",
        "\n",
        "\n",
        "print(\"Original Paragraph:\")\n",
        "print(paragraph)\n",
        "\n",
        "print(\"\\nTokenized Sentences:\")\n",
        "for i, sentence in enumerate(sentences, start=1):\n",
        "    print(f\"Sentence {i}: {sentence}\")\n",
        "\n",
        "print(\"\\nTokenized Words:\")\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZXEQ-ZRYtiL",
        "outputId": "378ac855-ba69-46ba-8602-23ba6d7c6e63"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Paragraph:\n",
            "\n",
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. \n",
            "Tokenization is one of the first steps in NLP, breaking text into sentences or words. It is crucial for tasks like text analysis, machine translation, and sentiment analysis.\n",
            "\n",
            "\n",
            "Tokenized Sentences:\n",
            "Sentence 1: \n",
            "Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n",
            "Sentence 2: Tokenization is one of the first steps in NLP, breaking text into sentences or words.\n",
            "Sentence 3: It is crucial for tasks like text analysis, machine translation, and sentiment analysis.\n",
            "\n",
            "Tokenized Words:\n",
            "['Natural', 'Language', 'Processing', '(', 'NLP', ')', 'is', 'a', 'field', 'of', 'artificial', 'intelligence', 'that', 'focuses', 'on', 'the', 'interaction', 'between', 'computers', 'and', 'humans', 'through', 'natural', 'language', '.', 'Tokenization', 'is', 'one', 'of', 'the', 'first', 'steps', 'in', 'NLP', ',', 'breaking', 'text', 'into', 'sentences', 'or', 'words', '.', 'It', 'is', 'crucial', 'for', 'tasks', 'like', 'text', 'analysis', ',', 'machine', 'translation', ',', 'and', 'sentiment', 'analysis', '.']\n"
          ]
        }
      ]
    }
  ]
}